# Workflow for Synthizer3d
# by Ambro86, adapted for cibuildwheel
name: Build Synthizer3d Wheels and Sdist

on:
  push: {}
  pull_request: {}

jobs:
  build_wheels:
    name: Build Wheels on ${{ matrix.os }} (${{ matrix.arch }})
    runs-on: ${{ matrix.os }}
    permissions: # Add this if you use pypa/gh-action-pypi-publish for deployment later
      id-token: write 
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest, macos-13, macos-14] # macos-14 for arm64
        arch: ["auto"] # cibuildwheel will pick appropriate archs for the runner
        include:
          - os: macos-13 # Intel
            arch: x86_64
          - os: macos-14 # Apple Silicon
            arch: arm64
          - os: ubuntu-latest
            arch: auto # will typically build x86_64, can add aarch64
          - os: windows-latest
            arch: auto # will build x86 and AMD64

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Run C/C++ code vendoring script (pre-cibuildwheel setup)
        # This needs to run once per job, sources will be used by cibuildwheel
        run: python synthizer-c/vendor.py synthizer-vendored

      # This step is crucial: Set up vcpkg OUTSIDE cibuildwheel for complex dependencies
      # It makes the compiled libraries available system-wide for cibuildwheel to find
      # (when CMAKE_PREFIX_PATH is set).
      - name: Set up vcpkg and dependencies
        id: vcpkg_setup # Give it an id to reference outputs if needed
        uses: lukka/run-vcpkg@v11
        with:
          # Determine vcpkg triplet based on OS and matrix.arch
          vcpkgTriplet: ${{ (matrix.os == 'windows-latest' && (matrix.arch == 'x86_64' && 'x64-windows' || 'x86-windows')) || \
                            (matrix.os == 'ubuntu-latest' && 'x64-linux') || \
                            (matrix.os == 'macos-13' && 'x64-osx') || \
                            (matrix.os == 'macos-14' && 'arm64-osx') }}
          # You might need to list your packages if vcpkg.json isn't picked up automatically
          # vcpkgArguments: 'fmt spdlog libsamplerate dr_libs stb vorbis ogg opus' # Example

      - name: Install vcpkg packages
        shell: bash # Use bash for cross-platform consistency here
        run: |
          echo "VCPKG_ROOT is $VCPKG_ROOT"
          echo "VCPKG_TRIPLET is ${{ env.VCPKG_DEFAULT_TRIPLET }}" # from lukka/run-vcpkg
          if [ -z "$VCPKG_ROOT" ]; then
            echo "Error: VCPKG_ROOT is not set."
            exit 1
          fi
          # Assuming vcpkg.json is in the root and defines your dependencies
          "$VCPKG_ROOT/vcpkg" install --triplet "$VCPKG_DEFAULT_TRIPLET"

          VCPKG_INSTALLED_DIR="$VCPKG_ROOT/installed/$VCPKG_DEFAULT_TRIPLET"
          echo "VCPKG_INSTALLED_DIR_PATH=$VCPKG_INSTALLED_DIR" >> $GITHUB_ENV
          echo "Determined VCPKG_INSTALLED_DIR_PATH: $VCPKG_INSTALLED_DIR"

      - name: Build wheels with cibuildwheel
        uses: pypa/cibuildwheel@v2.19.1 # Use the latest version
        env:
          # --- VCPKG Environment for cibuildwheel ---
          # Pass the vcpkg installed path to the build environment
          # Note: Adjust LD_LIBRARY_PATH/DYLD_LIBRARY_PATH as needed for your build system
          # inside the cibuildwheel environment.
          CIBW_ENVIRONMENT_WINDOWS: >
            CMAKE_PREFIX_PATH=${{ env.VCPKG_INSTALLED_DIR_PATH }}
          CIBW_ENVIRONMENT_LINUX: >
            CMAKE_PREFIX_PATH=${{ env.VCPKG_INSTALLED_DIR_PATH }}
            LD_LIBRARY_PATH=${{ env.VCPKG_INSTALLED_DIR_PATH }}/lib:$LD_LIBRARY_PATH
          CIBW_ENVIRONMENT_MACOS: >
            CMAKE_PREFIX_PATH=${{ env.VCPKG_INSTALLED_DIR_PATH }}
            DYLD_LIBRARY_PATH=${{ env.VCPKG_INSTALLED_DIR_PATH }}/lib:$DYLD_LIBRARY_PATH

          # --- Python Versions & Architectures ---
          # Let cibuildwheel build for a range of Pythons. It will skip unsupported ones.
          # For Python 3.13, ensure your dependencies and build system support it.
          CIBW_BUILD: "cp38-* cp39-* cp310-* cp311-* cp312-* cp313-*"
          CIBW_ARCHS_WINDOWS: ${{ (matrix.arch == 'auto' && 'x86 AMD64') || matrix.arch }}
          CIBW_ARCHS_LINUX: ${{ (matrix.arch == 'auto' && 'x86_64 aarch64') || matrix.arch }} # Add aarch64 if desired
          CIBW_ARCHS_MACOS: ${{ matrix.arch }} # Will be x86_64 for macos-13, arm64 for macos-14

          # --- Linux manylinux image ---
          # You might need a newer manylinux image if default doesn't have new enough GCC for vcpkg
          # CIBW_MANYLINUX_X86_64_IMAGE: manylinux_2_28
          # CIBW_MANYLINUX_AARCH64_IMAGE: manylinux_2_28

          # --- Build & Repair ---
          # Install build requirements like Cython via pyproject.toml's build-system.requires
          # If some tools are needed globally in the build env, use CIBW_BEFORE_ALL_LINUX etc.
          # For example, to install system packages for vcpkg on Linux:
          # CIBW_BEFORE_ALL_LINUX: >
          #   apt-get update &&
          #   apt-get install -y build-essential curl unzip tar ca-certificates pkg-config git &&
          #   rm -rf /var/lib/apt/lists/*
          # (Note: For vcpkg itself, it's often easier to install it in the CIBW_BEFORE_BUILD step
          #  or pre-install it on the runner as done above, then point CMAKE_PREFIX_PATH)

          CIBW_BUILD_VERBOSITY_WINDOWS: 3
          CIBW_BUILD_VERBOSITY_LINUX: 3
          CIBW_BUILD_VERBOSITY_MACOS: 3
          
          # For Windows, use delvewheel to bundle DLLs from vcpkg
          CIBW_REPAIR_WHEEL_COMMAND_WINDOWS: "delvewheel repair --add-path \"${{ env.VCPKG_INSTALLED_DIR_PATH }}\\bin;${{ env.VCPKG_INSTALLED_DIR_PATH }}\\lib\" -w {dest_dir} {wheel}"
          # Install delvewheel for the repair step
          CIBW_PIP_PACKAGES_WINDOWS: delvewheel

          # For macOS, delocate is default. Ensure delocate is installed if not default.
          CIBW_PIP_PACKAGES_MACOS: delocate

          # --- Skip builds ---
          # Example: CIBW_SKIP: "cp38-win_x86"

      - name: Upload Python Wheel Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: python-wheels-${{ matrix.os }}-${{ matrix.arch }}
          path: ./wheelhouse/*.whl # cibuildwheel puts wheels in ./wheelhouse by default

  build_sdist:
    name: Build Python sdist
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Set up Python (for sdist)
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'

      - name: Run C/C++ code vendoring script
        run: python synthizer-c/vendor.py synthizer-vendored

      - name: Install Python build dependencies (sdist)
        run: |
          python -m pip install --upgrade pip build
          # Ensure your pyproject.toml lists setuptools, wheel, scikit-build, cython etc.

      - name: Build Python sdist
        run: python -m build --sdist

      - name: Upload Python sdist Artifact
        uses: actions/upload-artifact@v4
        with:
          name: python-sdist
          path: dist/*.tar.gz

  deploy_pypi:
    name: Deploy to PyPI
    if: startsWith(github.ref, 'refs/tags') # Only run on tags
    needs: [build_wheels, build_sdist]
    runs-on: ubuntu-latest
    permissions:
      id-token: write # Required for trusted publishing
    steps:
      - name: Download all build artifacts
        uses: actions/download-artifact@v4
        with:
          path: ~/artifacts # All artifacts will be downloaded into subdirectories here

      - name: Set up Python for Twine
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Install Twine
        run: python -m pip install --upgrade pip twine

      - name: Display downloaded artifacts structure
        run: ls -R ~/artifacts

      - name: Upload to PyPI
        env:
          # Using trusted publishing (recommended)
          # TWINE_USERNAME: __token__ # PyPI expects this for API tokens
          # TWINE_PASSWORD: ${{ secrets.PYPI_API_TOKEN }} # Store your PyPI token as a GitHub secret
          TWINE_REPOSITORY_URL: https://upload.pypi.org/legacy/
        run: |
          echo "Listing all wheel and sdist files to be uploaded:"
          find ~/artifacts -name '*.whl' -print -exec echo \;
          find ~/artifacts -name '*.tar.gz' -print -exec echo \;
          # The downloaded artifacts will be in subfolders like ~/artifacts/python-wheels-ubuntu-latest-auto/
          # So we need to find them all.
          python -m twine upload --skip-existing $(find ~/artifacts -name '*.whl' -o -name '*.tar.gz')